# Conda

## 指令

激活环境：就会进入base环境，之后跟其他python安装一致。

```python
conda activate 
```

退出环境：

```python
conda deactivate
```

# Nvidia

直接上官网搜和自己电脑相配的显卡驱动（一般都是推荐最新的）驱动的版本一般不做要求，都是适配的（不考虑其稳定性的情况下）,下载放在/home/zcc目录下（方便寻找，不能放在中文目录下面）

安装的前提是**禁用nouveau驱动**

```
lsmod | grep nouveau			//如果输入之后没有输出，就说明已经禁用了
```

1. 查看GPU的使用情况（也可以验证驱动是否安装成功）

   ```
   nvidia-smi
   ```

2. 可以看系统是否已经连上了nvidia，正常会出现3个文件

   ```
   ls /dev/nvidia*
   ```

3. 卸载nvidia指令：

   ```
   sudo apt-get remove --purge nvidia*		//通用的卸载方式
   ```

   ```
   sudo /usr/bin/nvidia-uninstall    //在cuda安装时候附带安装的，可以用此卸载
   ```

4. 进入图形页面： **Alt + ctrl +F7 **   

   进入命令行：**Alt + ctrl +F1** 	

5. 在安装nvidia的时候需要关闭图形化界面

   ```
   sudo service lightdm stop
   ```

   在安装完成后重新打开图形化界面

   ```
    sudo service lightdm start
   ```

6. 该文件对所有人均可执行

   ```
   sudo chmod a+x NVIDIA-Linux-x86_64-440.36.run
   ```

   运行安装程序

   ```
   sudo ./NVIDIA-Linux-x86_64-440.36.run --dkms --no-opengl-files //表示只安装驱动文件，不安装OpenGL文件，Ubuntu的内核本身也有OpenGL、且与GUI显示息息相关，一旦NVIDIA的驱动覆写了OpenGL，在GUI需要动态链接OpenGL库的时候就引起问题
   ```

   安装过程中，会出现问是否安装**dkms**，选yes；是否**32位兼容**，选yes；**x-org**，建议no

# Cuda

1. 该文件对所有人均可执行	

```
sudo chmod a+x  cuda_8.0.44_linux.run 
```

​	运行cuda安装程序

```
sudo ./cuda_8.0.44_linux.run
```

​	首先会出现	一个文档，按**回车**让进度条到100%

​	问是否接受——accept

​	问是否安装nvidia——如果已经安装好驱动了，就选择no；否则，选择yes

​	其余均默认为yes/默认路径

​	提示是否安装openGL——如果是双显的系统，就选no（默认是no）

2. 卸载cuda

   注意不能进入到该目录下卸载，而是要在外面运行该语句

   ```
    sudo /usr/local/cuda-8.0/bin/uninstall_cuda_8.0.pl
   ```

   

# RCNN（区域CNN）

利用深度学习进行目标检测的开山之作。

大致思想：采用**selective research**方法预先获得候选区域（是较可能为物体），之后仅在这些**候选区域**上面采用**CNN**提取特征并判断。

## 目标检测

给定图片，能够找到物体的位置，并且标注出物体的种类（location+classification）

### classification——图像识别

输入图片—> 输出物体类别	评估：准确率  

CNN已经能够将图中的物体类别识别出来

### location——定位

输入图片—>输出物体在图片的位置(x, y, w, h) 评估：评价函数：交并比IOU（黑红边框的交集/黑红边框的并集，0~1，1时，即红黑边框完全重合）<img src="C:\Users\surface\AppData\Roaming\Typora\typora-user-images\image-20191201215223834.png" alt="image-20191201215223834" style="zoom:67%;" />

## 算法步骤

1. 候选区域生成：利用**selective research**方法对一张图片生成1000~2000个候选区域
2. 特征提取：对每个候选区域采用**CNN(卷积神经网络)提取特征**
3. 类别判断：特征送入每一类的**SVM分类器**中，判别是否属于该类
4. 位置精修：使用**回归器**精细修正候选框的位置

## 基础知识

### selective search——选择性搜索	

目标检测中，这是常用的区域提议算法(region proposal algorithm，即使用一些方法将图像划分为小的区域)

**exhaustive search**：穷举法，遍历每个像素点，但是搜索范围很大，计算量大，也导致提议的区域很多，所以不适合使用

selective search的优势：捕捉不同尺度；多样化；快速计算

#### Hierarchical Grouping Algorithm——分层分组算法

图像中**区域特征**比像素更有代表性

1. 计算所有**邻近区域**之间的**相似性**
2. **最相似**的区域被组合在一起
3. 计算合并区域和相邻区域的相似性
4. 重复2、3过程，直到整个图像变成一个地区

每次迭代产生的更大的区域并将其添加到区域提议列表中，从**小到大**创建从小的segments到大的segments的区域提案。

<img src="C:\Users\surface\AppData\Roaming\Typora\typora-user-images\image-20191202100123927.png" alt="image-20191202100123927" style="zoom:67%;" />

输入：图片（三通道）

输出：物体位置的可能结果L

算法原理：

1. 基于**图的图像分割**得到**初始分割区域**R = {r1, r2, ...,rn}
2. 初始化相似度集合 S=∅ 
3. 计算两两**相邻区域**之间的**相似度**，将其添加到相似度集合S中
4. 从集合S中找到相似度最大的两个区域ri和rj，将其合并为一个区域rt，从集合中删除ri和rj相关的相邻区域的相似度计算，再计算rt和相邻区域的相似度（即，和ri、rj的相邻区域），再将结果加入到相似度集合中。并且将新的区域加入到区域R中。重复操作，直到S=∅
5. 获取每个区域的边界框（bounding boxes）L，输出位置的可能结果

####  **Diversification Strategies** ——多元化策略

即在计算相似度的时候，考量的点是多样的，使得划分的完全。如下图，每个图都应该使用不同的划分策略，才能划分正确：（a）物体之间有层次性；（b）颜色可以为划分策略；（c）纹理区分；（d）物体有层次性

<img src="C:\Users\surface\AppData\Roaming\Typora\typora-user-images\image-20191202105746828.png" alt="image-20191202105746828" style="zoom: 67%;" />



1.  利用各种不同不变性的色彩空间：将原始色彩空间->八种色彩空间

   <img src="C:\Users\surface\AppData\Roaming\Typora\typora-user-images\image-20191202110935609.png" alt="image-20191202110935609" style="zoom: 50%;" />

2.  采用不同的相似性度量：

   - **颜色相似度衡量**（ 对各个通道计算颜色直方图，然后取各个对应bins的直方图最小值。 ）；
   - **纹理相似度衡量**（ 计算每个区域的快速sift特征 ）；
   - **优先合并小区域**（ 保证在图像每个位置都是多尺度的在合并 ）；
   - **形状重合度衡量**（ 合并后的区域的bounding box越小，其重合度越高 ） ；
   - **综合各种距离**（加权计算各种相似度衡量距离）

3.  改变起始区域

   因为是基于图的图像分割得到的初始分割区域，所以初始分割区域影响很大，所以通过多种参数选取以产生初始化图像分割，也是多样性的一种扩充

#### 给区域打分

上述步骤能得到很多区域，但是需要衡量每个**区域能作为目标的可能性是不同的**，**每个区域有不同的分数**，从而根据需要筛选候选区域。

（文章中）给予**最先合并的图片较大的权重**，最后完整的图片的权重为1，倒数第二为2以此类推。权重重合就给乘上一个随机数，相同区域多次出现就权重叠加。所有区域有不同的分数，根据需要筛选目标区域数目，选择分数最好的n个候选区域。

# anchor目标检测

anchor box ：锚框，是固定的参考框

首先预设一组不同尺度不同位置的**固定参考框**，覆盖几乎所有位置和尺度，每个参考框负责检测与其交并比大于阈值 (训练预设值，常用0.5或0.7) 的目标，anchor技术将问题转换为"**这个固定参考框中有没有认识的目标，目标框偏离参考框多远**"，不再需要多尺度遍历滑窗，真正实现了又好又快



# mmdetection

## 训练

1. 默认需要GPU才能运行

2. 使用tool/train.py

3. 目前跑的是单GPU运行：

   指令：python tools/train.py configs/mask_rcnn_r50_fpn_1x.py --gpus 1 –work_dir workdirs 

   分别表示：训练文件，配置文件，GPU数目（默认为1），模型checkpoint 文件的输出目录（迭代过程中保留一次数据）

4. train.py的源码

## 测试

1. 默认需要GPU才能运行

2. 使用tool/test.py

3. 目前跑的是单GPU运行：

   指令：python tools/test.py configs/cascade_rcnn_r50_fpn_1x.py checkpoints/cascade_ecnn_r50_fpn_1x_20190501-3b6211ab.pth --gpus 1 --out out.pkl

   分别表示：测试文件，配置文件（和训练中的配置文件一样），训练结果文件（即训练的输出文件，在checkpoints目录下，如果是自己训练的结果，就放在了训练结果自定义的目录下面，后缀为.pth），GPU数目（默认为1），输出的文件名字

4. test.py的源码





 