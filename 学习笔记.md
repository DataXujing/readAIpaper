# Conda

## 指令

激活环境：就会进入base环境，之后跟其他python安装一致。

```python
conda activate 
```

退出环境：

```python
conda deactivate
```

# Nvidia

直接上官网搜和自己电脑相配的显卡驱动（一般都是推荐最新的）驱动的版本一般不做要求，都是适配的（不考虑其稳定性的情况下）,下载放在/home/zcc目录下（方便寻找，不能放在中文目录下面）

安装的前提是**禁用nouveau驱动**

```
lsmod | grep nouveau			//如果输入之后没有输出，就说明已经禁用了
```

1. 查看GPU的使用情况（也可以验证驱动是否安装成功）

   ```
   nvidia-smi
   ```

2. 可以看系统是否已经连上了nvidia，正常会出现3个文件

   ```
   ls /dev/nvidia*
   ```

3. 卸载nvidia指令：

   ```
   sudo apt-get remove --purge nvidia*		//通用的卸载方式
   ```

   ```
   sudo /usr/bin/nvidia-uninstall    //在cuda安装时候附带安装的，可以用此卸载
   ```

4. 进入图形页面： **Alt + ctrl +F7 **   

   进入命令行：**Alt + ctrl +F1** 	

5. 在安装nvidia的时候需要关闭图形化界面

   ```
   sudo service lightdm stop
   ```

   在安装完成后重新打开图形化界面

   ```
    sudo service lightdm start
   ```

6. 该文件对所有人均可执行

   ```
   sudo chmod a+x NVIDIA-Linux-x86_64-440.36.run
   ```

   运行安装程序

   ```
   sudo ./NVIDIA-Linux-x86_64-440.36.run --dkms --no-opengl-files //表示只安装驱动文件，不安装OpenGL文件，Ubuntu的内核本身也有OpenGL、且与GUI显示息息相关，一旦NVIDIA的驱动覆写了OpenGL，在GUI需要动态链接OpenGL库的时候就引起问题
   ```

   安装过程中，会出现问是否安装**dkms**，选yes；是否**32位兼容**，选yes；**x-org**，建议no

# Cuda

1. 该文件对所有人均可执行	

```
sudo chmod a+x  cuda_8.0.44_linux.run 
```

​	运行cuda安装程序

```
sudo ./cuda_8.0.44_linux.run
```

​	首先会出现	一个文档，按**回车**让进度条到100%

​	问是否接受——accept

​	问是否安装nvidia——如果已经安装好驱动了，就选择no；否则，选择yes

​	其余均默认为yes/默认路径

​	提示是否安装openGL——如果是双显的系统，就选no（默认是no）

2. 卸载cuda

   注意不能进入到该目录下卸载，而是要在外面运行该语句

   ```
    sudo /usr/local/cuda-8.0/bin/uninstall_cuda_8.0.pl
   ```

   

# RCNN（区域CNN）

利用深度学习进行目标检测的开山之作。

大致思想：采用**selective research**方法预先获得候选区域（是较可能为物体），之后仅在这些**候选区域**上面采用**CNN**提取特征并判断。

## 1. 目标检测的概念

给定图片，能够找到物体的位置，并且标注出物体的种类（location+classification）

### classification——图像识别

输入图片—> 输出物体类别	评估：准确率  

CNN已经能够将图中的物体类别识别出来

### location——定位

输入图片—>输出物体在图片的位置(x, y, w, h) 评估：评价函数：交并比IOU（黑红边框的交集/黑红边框的并集，0~1，1时，即红黑边框完全重合）<img src="markdown_pic\image-20191201215223834.png" alt="image-20191201215223834" style="zoom:67%;" />

## 2. 算法步骤

1. 候选区域生成：利用**selective research**方法对一张图片生成1000~2000个候选区域（region proposals）
2. 特征提取：对每个候选区域采用**CNN(卷积神经网络)提取特征**
3. 类别判断：特征送入每一类的**SVM分类器**中，判别是否属于该类
4. 位置精修：使用**回归器**精细修正候选框的位置

## 3. 基础知识

### 1. selective search——选择性搜索	

目标检测中，这是常用的区域提议算法(region proposal algorithm，即使用一些方法将图像划分为小的区域)

**exhaustive search**：穷举法，遍历每个像素点，但是搜索范围很大，计算量大，也导致提议的区域很多，所以不适合使用

selective search的优势：捕捉不同尺度；多样化；快速计算

#### 1. Hierarchical Grouping Algorithm——分层分组算法

图像中**区域特征**比像素更有代表性

1. 计算所有**邻近区域**之间的**相似性**
2. **最相似**的区域被组合在一起
3. 计算合并区域和相邻区域的相似性
4. 重复2、3过程，直到整个图像变成一个地区

每次迭代产生的更大的区域并将其添加到区域提议列表中，从**小到大**创建从小的segments到大的segments的区域提案。

<img src="markdown_pic\image-20191202100123927.png" alt="image-20191202100123927" style="zoom:67%;" />

输入：图片（三通道）

输出：物体位置的可能结果L

算法原理：

1. 基于**图的图像分割**得到**初始分割区域**R = {r1, r2, ...,rn}
2. 初始化相似度集合 S=∅ 
3. 计算两两**相邻区域**之间的**相似度**，将其添加到相似度集合S中
4. 从集合S中找到相似度最大的两个区域ri和rj，将其合并为一个区域rt，从集合中删除ri和rj相关的相邻区域的相似度计算，再计算rt和相邻区域的相似度（即，和ri、rj的相邻区域），再将结果加入到相似度集合中。并且将新的区域加入到区域R中。重复操作，直到S=∅
5. 获取每个区域的边界框（bounding boxes）L，输出位置的可能结果

####  2. **Diversification Strategies** ——多元化策略

即在计算相似度的时候，考量的点是多样的，使得划分的完全。如下图，每个图都应该使用不同的划分策略，才能划分正确：（a）物体之间有层次性；（b）颜色可以为划分策略；（c）纹理区分；（d）物体有层次性

<img src="markdown_pic\image-20191202105746828.png" alt="image-20191202105746828" style="zoom: 67%;" />



1.  利用各种不同不变性的色彩空间：将原始色彩空间->八种色彩空间

   <img src="markdown_pic\image-20191202110935609.png" alt="image-20191202110935609" style="zoom: 50%;" />

2.  采用不同的相似性度量：

   - **颜色相似度衡量**（ 对各个通道计算颜色直方图，然后取各个对应bins的直方图最小值。 ）；
   - **纹理相似度衡量**（ 计算每个区域的快速sift特征 ）；
   - **优先合并小区域**（ 保证在图像每个位置都是多尺度的在合并 ）；
   - **形状重合度衡量**（ 合并后的区域的bounding box越小，其重合度越高 ） ；
   - **综合各种距离**（加权计算各种相似度衡量距离）

3.  改变起始区域

   因为是基于图的图像分割得到的初始分割区域，所以初始分割区域影响很大，所以通过多种参数选取以产生初始化图像分割，也是多样性的一种扩充

#### 给区域打分

上述步骤能得到很多区域，但是需要衡量每个**区域能作为目标的可能性是不同的**，**每个区域有不同的分数**，从而根据需要筛选候选区域。

（文章中）给予**最先合并的图片较大的权重**，最后完整的图片的权重为1，倒数第二为2以此类推。权重重合就给乘上一个随机数，相同区域多次出现就权重叠加。所有区域有不同的分数，根据需要筛选目标区域数目，选择分数最好的n个候选区域。

### 2. CNN经典模型——AlexNet

是一个深层卷积神经网络，在图像识别分类效果远超其他，推广了CNN。和普通的CNN模型来说：

1. 采用非线性激活函数：**ReLU**；
2. 防止过拟合的方法：**Dropout**，**数据扩充**；
3. **多GPU**实现；
4. **LRN归一化层**的使用

#### 1. 使用ReLU激活函数

sigmoid等非线性函数，易出现梯度弥散或梯度饱和问题（输入的值很小或是很大时，神经元的梯度接近于0；<u>反向传播时因为需要乘上一个Sigmoid导数，会造成梯度越来越小，导致网络变的很难学习</u> ）

ReLU函数

<img src="markdown_pic\image-20191202212716240.png" alt="image-20191202212716240" style="zoom:50%;" />

因为导数为1，**计算量减少**，**收敛速度加快**

#### 2. 数据扩充

提供数据的量增加，算法的准确率也会提高，能够避免过拟合，能够进一步增大、加深网络结构。但训练数据集的数量有限的情况下，对**已有的数据进行变换**而扩充数据集。

常用的有：水平翻转；随机裁剪；平移变换；颜色、光照变换。

AlexNet在训练时，用到了：

-  **随机裁剪**，对256×256的图片进行随机裁剪到224×224，然后进行水平翻转，相当于将样本数量增加了（（256-224）^2）×2=2048倍； 
-  测试的时候，对左上、右上、左下、右下、中间分别做了5次裁剪，然后翻转，共**10个裁剪**，之后对**结果求平均**；
-  **对RGB空间做PCA（主成分分析）**，然后对主成分做一个（0, 0.1）的高斯扰动，也就是对颜色、光照作变换， 结果使错误率又下降了1%。（主成分分析，用来数据降维，利用线性变换，将当前空间的数据投影到另外的一个空间中，使得数据维度降低）

#### 3. 重叠池化

一般的池化是不重叠的，池化窗口和步长相同，池化出现在**池化层**，用来压缩数据和参数量，以减少过拟合。一般都是选择区域平均或是区域最大

AlexNet使用的池化是可重叠的，即池化的窗口大于步长。且是**最大重叠池化**。池化重叠池化可以避免过拟合。

#### 4. 局部归一化（LRN）

归一化，即被激活的神经元抑制相邻的神经元，局部归一化即实现**局部抑制**。将值**归一化到某个范围**内，因为ReLU的值可能会很大。响应比较**大**的值变得**相对更大**，并抑制其他反馈较小的神经元 ，提高**网络的泛化能力**（ 因为一旦每批训练数据的分布各不相同(batch 梯度下降)，那么网络就要在每次迭代都去学习适应不同的分布，这样将会大大降低网络的训练速度 ）

公式如下：i表示第i个核在位置（x,y）运用激活函数ReLU后的输出；n是同一位置上临近的kernal map的数目；N是kernal的总数 

<img src="markdown_pic\image-20191202222704451.png" alt="image-20191202222704451" style="zoom:67%;" />

<img src="markdown_pic\image-20191202222639437.png" alt="image-20191202222639437" style="zoom:67%;" />

#### 5. Dropout

为了**防止过拟合**，通过**修改网络本身的结构**来实现。对于某层神经元，通过定义的概率将**神经元置为0**，即该神经元不参与前向和后向传播。但保证输入层和输出层神经元个数不变，其余均按照普通的学习方法进行。下一次迭代的时候，又**随机置0一批新的神经元**。——这使得每次迭代生成的神经网络均不同。

<img src="markdown_pic\image-20191202223250119.png" alt="image-20191202223250119" style="zoom:67%;" />

#### 6. 多GPU训练

**加快训练速度**，将一半的神经元放在一个GPU上，另一半放在另一个上。

#### 7. 逐层解析AlexNet网络结构

<img src="markdown_pic\image-20191202224306979.png" alt="image-20191202224306979" style="zoom:80%;" />

共8层，前5层为卷积层，后3层为全连接层



## 4. 各阶段详解

总体思路：对每个输入图片产生**2000个不分种类**的候选区域 -> 使用CNN提取每个候选区域**固定长度的特征向量**（4096维）-> 对取出的特征向量使用**特定种类的线性SVM**进行分类。即找出候选框 -> 利用CNN提取特征向量 -> 利用SVM进行特征向量分类。

### 1. 候选框搜索阶段

用selective research方法找出2000个候选框

候选框为矩形，但是大小不同，而CNN要求输入图片的大小是固定的，所以要对每个候选框进行缩放。如图(A)

各向异性缩放——不管照片是否扭曲，直接将像素值修改到指定大小。如图(D)

各向同性缩放——先扩充后裁剪（在原始图片中扩展候选区域为正方形，然后再裁剪到指定大小），如图(B)；先裁剪后扩充（先将候选区域从图片中裁剪出来，然后用固定的颜色填充剩下的区域，背景颜色是候选框像素颜色均值），如图(C)。

此外还有一个padding处理。1，3行为padding=0的结果；2，4为padding=16的结果（即，还加了原图的边界框）

<img src="markdown_pic\image-20191202204106300.png" alt="image-20191202204106300" style="zoom:67%;" />

根据结果分析——各向异性缩放+padding=16效果最好

### 2. CNN特征提取阶段⭐

#### 1.算法实现

网络结构设计阶段：选择Alexnet；VGG16



# anchor目标检测

anchor box ：锚框，是固定的参考框

首先预设一组不同尺度不同位置的**固定参考框**，覆盖几乎所有位置和尺度，每个参考框负责检测与其交并比大于阈值 (训练预设值，常用0.5或0.7) 的目标，anchor技术将问题转换为"**这个固定参考框中有没有认识的目标，目标框偏离参考框多远**"，不再需要多尺度遍历滑窗，真正实现了又好又快



# mmdetection

## 训练

1. 默认需要GPU才能运行

2. 使用tool/train.py

3. 目前跑的是单GPU运行：

   指令：python tools/train.py configs/mask_rcnn_r50_fpn_1x.py --gpus 1 –work_dir workdirs 

   分别表示：训练文件，配置文件，GPU数目（默认为1），模型checkpoint 文件的输出目录（迭代过程中保留一次数据）

4. train.py的源码

## 测试

1. 默认需要GPU才能运行

2. 使用tool/test.py

3. 目前跑的是单GPU运行：

   指令：python tools/test.py configs/cascade_rcnn_r50_fpn_1x.py checkpoints/cascade_ecnn_r50_fpn_1x_20190501-3b6211ab.pth --gpus 1 --out out.pkl

   分别表示：测试文件，配置文件（和训练中的配置文件一样），训练结果文件（即训练的输出文件，在checkpoints目录下，如果是自己训练的结果，就放在了训练结果自定义的目录下面，后缀为.pth），GPU数目（默认为1），输出的文件名字

4. test.py的源码





 